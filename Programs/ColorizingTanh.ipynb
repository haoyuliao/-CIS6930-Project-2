{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "talented-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n",
    "import torch, torchvision, os, cv2\n",
    "from torch.utils.data import random_split, Dataset\n",
    "from torch.nn import Tanh, Linear, ReLU, Sequential, Conv2d, MaxPool2d, Sigmoid, BatchNorm2d, Flatten, ConvTranspose2d\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class augementData(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "    \n",
    "def saveRes2Img(inputs, labels, outputs):\n",
    "    inputsNP = inputs.cpu().data.numpy()\n",
    "    labelsNP = labels.cpu().data.numpy()\n",
    "    outputsNP = outputs.cpu().data.numpy()\n",
    "    rowN = 15\n",
    "    for n in range(len(inputsNP)):\n",
    "        ture_l = inputsNP[n,0,:,:]*255\n",
    "        ture_a = (labelsNP[n,0,:,:]*127)+128\n",
    "        ture_b = (labelsNP[n,1,:,:]*127)+128\n",
    "        pred_a = (outputsNP[n,0,:,:]*127)+128\n",
    "        pred_b = (outputsNP[n,1,:,:]*127)+128\n",
    "        '''\n",
    "        ture_l = np.array(inputsNP[n,0,:,:])*255\n",
    "        ture_a = np.array(labelsNP[n,0,:,:])*255\n",
    "        ture_b = np.array(labelsNP[n,1,:,:])*255\n",
    "        pred_a = np.array(outputsNP[n,0,:,:])*255\n",
    "        pred_b = np.array(outputsNP[n,1,:,:])*255\n",
    "        '''\n",
    "        ture_LAB = np.array([ture_l,ture_a,ture_b])\n",
    "        #ture_LAB = (ture_LAB+128)*127\n",
    "        pred_LAB = np.array([ture_l,pred_a,pred_b])\n",
    "        #pred_LAB = (pred_LAB+128)*127\n",
    "        ture_LAB = np.moveaxis(ture_LAB, 0, -1) #Reshape channeL from  [C, H, W] to [H, W, C]\n",
    "        pred_LAB = np.moveaxis(pred_LAB, 0, -1) #Reshape channeL from  [C, H, W] to [H, W, C]\n",
    "        imgTrueRGB = cv2.cvtColor(np.uint8(ture_LAB), cv2.COLOR_LAB2RGB)\n",
    "        imgPredRGB = cv2.cvtColor(np.uint8(pred_LAB), cv2.COLOR_LAB2RGB)\n",
    "        imgGrayRGB = cv2.cvtColor(imgTrueRGB, cv2.COLOR_RGB2GRAY)\n",
    "        if n == 0 or (n+1) % rowN == 1:\n",
    "            imgTempTrue = imgTrueRGB\n",
    "            imgTempPred = imgPredRGB\n",
    "            imgTempGray = imgGrayRGB\n",
    "        else:\n",
    "            imgTempTrue = np.hstack((imgTempTrue, imgTrueRGB))\n",
    "            imgTempPred = np.hstack((imgTempPred, imgPredRGB))\n",
    "            imgTempGray = np.hstack((imgTempGray, imgGrayRGB))\n",
    "        if (n+1) % rowN == 0:\n",
    "            if n+1 == rowN:\n",
    "                imgGroupTrue = imgTempTrue\n",
    "                imgGroupPred = imgTempPred\n",
    "                imgGroupGray = imgTempGray\n",
    "            else:    \n",
    "                imgGroupTrue = np.vstack((imgGroupTrue, imgTempTrue))\n",
    "                imgGroupPred = np.vstack((imgGroupPred, imgTempPred))\n",
    "                imgGroupGray = np.vstack((imgGroupGray, imgTempGray))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupTrue)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('TrueRes.png')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupPred)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('PredRes.png')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupGray, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('GrayRes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "round-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"./face_images/\"\n",
    "_, _, files = next(os.walk(img_dir))\n",
    "dataBGR = []\n",
    "dataLAB = []\n",
    "for f1 in files:\n",
    "    img = cv2.imread(img_dir+f1)\n",
    "    dataBGR.append(img)\n",
    "    imageLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    dataLAB.append(imageLAB)\n",
    "    \n",
    "dataBGR = np.array(dataBGR, dtype = np.float32) #Change data type into float 32.\n",
    "dataLAB = np.array(dataLAB, dtype = np.float32) #Change data type into float 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "stunning-graduation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#dataLAB = np.zeros((750,128,128,3), dtype = np.float32)\\ndataLAB[:,:,:,0] = dataLAB[:,:,:,0] #Change L reange into [0, 1] in the training part. Please go to training section. ex. data[0] / 255\\ndataLAB[:,:,:,1] = dataLAB[:,:,:,1] #Change a* and b* reange into [-1, 1] in the training part. Please go to training section. ex. (data[2]-128)/ 255\\ndataLAB[:,:,:,2] = dataLAB[:,:,:,2] #Change a* and b* reange into [-1, 1] in the training part. Please go to training section. ex. (data[2]-128)/ 255\\n#print(dataLAB.shape)\\ndataLAB = np.moveaxis(dataLAB, -1, 1) #Reshape channeL from [B, H, W, C] to [B, C, H, W]\\ndataLAB = dataLAB[torch.randperm(dataLAB.shape[0],generator=torch.random.manual_seed(42))] #shuffle with random seed 42 to make sure each round with same samples pool.\\nlengths = [int(len(dataLAB)*0.9), int(len(dataLAB)*0.1)]\\ntrainLAB, testLAB = random_split(dataLAB, lengths ,generator=torch.random.manual_seed(42)) #Shuffle data with random seed 42 before split train and test\\ntrainLAB = np.array(trainLAB)\\ntestLAB = np.array(testLAB)\\n\\nprint(dataLAB[:,:,:,0].max())\\nprint(dataLAB[:,:,:,1].max())\\nprint(dataLAB[:,:,:,2].max())\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image data types and what they mean!!!\n",
    "# https://scikit-image.org/docs/dev/user_guide/data_types.html\n",
    "# Data type\n",
    "# Range\n",
    "# uint8\n",
    "# 0 to 255\n",
    "# uint16\n",
    "# 0 to 65535\n",
    "# uint32\n",
    "# 0 to 232 - 1\n",
    "# float\n",
    "# -1 to 1 or 0 to 1\n",
    "# int8\n",
    "# -128 to 127\n",
    "# int16\n",
    "# -32768 to 32767\n",
    "# int32\n",
    "# -231 to 231 - 1\n",
    "\n",
    "#According to openCV documents, the range of L*, B*, C* in openCV are expressed as:\n",
    "#Articel ource https://rodrigoberriel.com/2014/11/opencv-color-spaces-splitting-channels/#:~:text=The%20Lab%20ranges%20are%3A,(1%20%3E%20L%20%3E%20255)\n",
    "#0 > L > 100 ⇒ OpenCV range = L*255/100 (1 > L > 255)\n",
    "#-127 > a > 127 ⇒ OpenCV range = a + 128 (1 > a > 255)\n",
    "#-127 > b > 127 ⇒ OpenCV range = b + 128 (1 > b > 255)\n",
    "\n",
    "dataLAB = dataLAB / 255 #Change reange into [0, 1] and #Change a* and b* reange into [-1, 1] in the training part. Please go to training section. ex. (data[2]*255-128)/ 127\n",
    "dataLAB = np.moveaxis(dataLAB, -1, 1) #Reshape channeL from [B, H, W, C] to [B, C, H, W]\n",
    "dataLAB = dataLAB[torch.randperm(dataLAB.shape[0],generator=torch.random.manual_seed(42))] #shuffle with random seed 42 to make sure each round with same samples pool.\n",
    "lengths = [int(len(dataLAB)*0.9), int(len(dataLAB)*0.1)]\n",
    "trainLAB, testLAB = random_split(dataLAB, lengths ,generator=torch.random.manual_seed(42)) #Shuffle data with random seed 42 before split train and test\n",
    "trainLAB = np.array(trainLAB)\n",
    "testLAB = np.array(testLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "laden-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.9 s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "trainLABTensor = torch.tensor(trainLAB)\n",
    "trainLABTensorx10 = torch.clone(trainLABTensor)\n",
    "for i in range(9):\n",
    "    trainLABTensorx10 = torch.cat((trainLABTensorx10, torch.clone(trainLABTensor)), 0)\n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop((128,128),scale=(0.6, 1.0)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "trainLABTensorx10Aug = augementData(trainLABTensorx10,transform) #Augement train data.\n",
    "\n",
    "trainData = [] \n",
    "trainLx10 = [] #Input L*\n",
    "trainAx10 = [] #Matrix a* #Label\n",
    "trainBx10 = [] #Matrix b* #Label\n",
    "trainAvg_ax10 = [] #scalar mean a* #Label\n",
    "trainAvg_bx10 = [] #scalar mean b* #Label\n",
    "i = 0\n",
    "for t in trainLABTensorx10Aug:\n",
    "    meanA = torch.mean(t[1])\n",
    "    meanB = torch.mean(t[2]) #trainLABTensorx10Aug[i,0,:,:]\n",
    "    #print(np.array(trainLABTensorx10Aug[i,0,:,:]).shape)\n",
    "    wh = len(t[0])\n",
    "    trainData.append([torch.reshape(t[0], (1, wh, wh)), torch.tensor([meanA, meanB]), \n",
    "                      torch.tensor([np.array(t[1]), np.array(t[2])])])\n",
    "    trainLx10.append(t[0])\n",
    "    trainAx10.append(t[1])\n",
    "    trainBx10.append(t[2])\n",
    "    trainAvg_ax10.append(meanA)\n",
    "    trainAvg_bx10.append(meanB)\n",
    "    i+=1\n",
    "trainAvg_ax10, trainAvg_bx10 = np.array(trainAvg_ax10), np.array(trainAvg_bx10)     \n",
    "trainlabelAvgABx10 = np.stack((trainAvg_ax10, trainAvg_bx10),axis=1)\n",
    "trainLoader = torch.utils.data.DataLoader(trainData, shuffle=True, batch_size=100)\n",
    "\n",
    "testDataL = testLAB[:,0,:,:] #Input L\n",
    "testDataL = testDataL.reshape((testDataL.shape[0],1,testDataL.shape[1],testDataL.shape[2]))\n",
    "testDataA = testLAB[:,1,:,:] #a* matrix\n",
    "testDataA = testDataA.reshape((testDataA.shape[0],1,testDataA.shape[1],testDataA.shape[2]))\n",
    "testDataB = testLAB[:,2,:,:] #b* matrix\n",
    "testDataB = testDataB.reshape((testDataB.shape[0],1,testDataB.shape[1],testDataB.shape[2]))\n",
    "testAvg_a = testLAB.mean(axis=(2,3))[:,1] #Get label mean of each a* \n",
    "testAvg_b = testLAB.mean(axis=(2,3))[:,2] #Get label mean of each b*\n",
    "testDataL = torch.tensor(testDataL) #Test input\n",
    "testlabelAvgAB = np.stack((testAvg_a, testAvg_b),axis=1)\n",
    "testlabelAvgAB = torch.tensor(testlabelAvgAB) #Test output label\n",
    "\n",
    "testData = []\n",
    "for i in range(len(testDataL)):\n",
    "    testData.append([testDataL[i], testlabelAvgAB[i], torch.tensor([testDataA[i][0], testDataB[i][0]])])\n",
    "testLoader = torch.utils.data.DataLoader(testData, shuffle=False, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "complicated-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Sequential(\n",
    "            # Defining 1st 2D convolution layer\n",
    "            Conv2d(1, 3, kernel_size=3, stride=1, padding=1), #128@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 2nd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #64@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 3rd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #32@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 4th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #16@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@16@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@32@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@64@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 2, 4, stride=2, padding=1), #@128@3\n",
    "            Tanh()\n",
    "        )\n",
    "net = net.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-approval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch: 1, MSE_Loss: 0.0069492882\n",
      "Train epoch: 2, MSE_Loss: 0.0023371150\n",
      "Train epoch: 3, MSE_Loss: 0.0022862047\n",
      "Train epoch: 4, MSE_Loss: 0.0022696327\n",
      "Train epoch: 5, MSE_Loss: 0.0022629212\n",
      "Train epoch: 6, MSE_Loss: 0.0022549855\n",
      "Train epoch: 7, MSE_Loss: 0.0022513923\n",
      "Train epoch: 8, MSE_Loss: 0.0022468131\n",
      "Train epoch: 9, MSE_Loss: 0.0022398571\n",
      "Train epoch: 10, MSE_Loss: 0.0022377640\n",
      "Train epoch: 11, MSE_Loss: 0.0022348935\n",
      "Train epoch: 12, MSE_Loss: 0.0022331839\n",
      "Train epoch: 13, MSE_Loss: 0.0022312981\n",
      "Train epoch: 14, MSE_Loss: 0.0022290293\n",
      "Train epoch: 15, MSE_Loss: 0.0022253656\n",
      "Train epoch: 16, MSE_Loss: 0.0022210383\n",
      "Train epoch: 17, MSE_Loss: 0.0022209837\n",
      "Train epoch: 18, MSE_Loss: 0.0022162376\n",
      "Train epoch: 19, MSE_Loss: 0.0022155290\n",
      "Train epoch: 20, MSE_Loss: 0.0022082723\n",
      "Train epoch: 21, MSE_Loss: 0.0022072460\n",
      "Train epoch: 22, MSE_Loss: 0.0022030447\n",
      "Train epoch: 23, MSE_Loss: 0.0021951264\n",
      "Train epoch: 24, MSE_Loss: 0.0021916529\n",
      "Train epoch: 25, MSE_Loss: 0.0021845718\n",
      "Train epoch: 26, MSE_Loss: 0.0021819417\n",
      "Train epoch: 27, MSE_Loss: 0.0021739665\n",
      "Train epoch: 28, MSE_Loss: 0.0021727197\n",
      "Train epoch: 29, MSE_Loss: 0.0021599259\n",
      "Train epoch: 30, MSE_Loss: 0.0021546369\n",
      "Train epoch: 31, MSE_Loss: 0.0021506055\n",
      "Train epoch: 32, MSE_Loss: 0.0021457886\n",
      "Train epoch: 33, MSE_Loss: 0.0021384472\n",
      "Train epoch: 34, MSE_Loss: 0.0021340483\n",
      "Train epoch: 35, MSE_Loss: 0.0021265183\n",
      "Train epoch: 36, MSE_Loss: 0.0021181146\n",
      "Train epoch: 37, MSE_Loss: 0.0021160727\n",
      "Train epoch: 38, MSE_Loss: 0.0021072543\n",
      "Train epoch: 39, MSE_Loss: 0.0021039195\n",
      "Train epoch: 40, MSE_Loss: 0.0020983707\n",
      "Train epoch: 41, MSE_Loss: 0.0020892813\n",
      "Train epoch: 42, MSE_Loss: 0.0020827414\n",
      "Train epoch: 43, MSE_Loss: 0.0020711664\n",
      "Train epoch: 44, MSE_Loss: 0.0020676329\n",
      "Train epoch: 45, MSE_Loss: 0.0020582263\n",
      "Train epoch: 46, MSE_Loss: 0.0020499757\n",
      "Train epoch: 47, MSE_Loss: 0.0020454261\n",
      "Train epoch: 48, MSE_Loss: 0.0020375996\n",
      "Train epoch: 49, MSE_Loss: 0.0020270931\n",
      "Train epoch: 50, MSE_Loss: 0.0020188980\n",
      "Train epoch: 51, MSE_Loss: 0.0020091448\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "trainTestLog = open(\"ColorizingTanhTrainTestLogEP1000.txt\",\"w+\") \n",
    "n_epoch = 1000\n",
    "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "#epoch = 0\n",
    "#while True:\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #inputs, labels = data[0].cuda(), data[1].cuda() #Reg\n",
    "        inputs, labels = data[0].cuda(), (data[2].cuda()*255-128)/127 #Color Change a* b* in [-1 ,1]\n",
    "        #print(labels[0].min())\n",
    "        #print(data[2][0])\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "    logStr = 'Train epoch: %d, MSE_Loss: %.10f' % (epoch + 1, train_loss/ (i+1))\n",
    "    trainTestLog.write(logStr+'\\n') #Save training records into log.\n",
    "    print(logStr)\n",
    "    epoch += 1\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './ColorizingTanhdWithLR0.1EP1000.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testLoader, 0):\n",
    "        #inputs, labels = data[0].cuda(), data[1].cuda() #Reg\n",
    "        inputs, labels = data[0].cuda(), (data[2].cuda()*255-128)/127 #Color Change a* b* in [-1 ,1]\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print statistics\n",
    "        test_loss += loss.item()\n",
    "        saveRes2Img(inputs, labels, outputs)        \n",
    "    n_samples = (i+1)*len(outputs)       \n",
    "\n",
    "logStr = 'Test MSE of the network on the %d test samples: %.10f' % (n_samples, test_loss/(i+1))\n",
    "print(logStr)\n",
    "trainTestLog.write(logStr+'\\n') #Save training records into log.\n",
    "trainTestLog.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-leone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
