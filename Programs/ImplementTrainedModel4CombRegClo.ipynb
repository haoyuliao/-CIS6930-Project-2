{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n",
    "import torch, torchvision, os, cv2\n",
    "from torch.utils.data import random_split, Dataset\n",
    "from torch.nn import Tanh, Linear, ReLU, Sequential, Conv2d, MaxPool2d, Sigmoid, BatchNorm2d, Flatten, ConvTranspose2d\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class augementData(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        item = self.transform(item)\n",
    "        return item\n",
    "\n",
    "def saveRes2Img(inputs, labels, outputs,saveImgPath):\n",
    "    inputsNP = inputs.cpu().data.numpy()\n",
    "    labelsNP = labels.cpu().data.numpy()\n",
    "    outputsNP = outputs.cpu().data.numpy()\n",
    "    rowN = 15\n",
    "    for n in range(len(inputsNP)):\n",
    "        ture_l = np.array(inputsNP[n,0,:,:])\n",
    "        ture_a = np.array(labelsNP[n,0,:,:])\n",
    "        ture_b = np.array(labelsNP[n,1,:,:])\n",
    "        pred_a = np.array(outputsNP[n,0,:,:])\n",
    "        pred_b = np.array(outputsNP[n,1,:,:])\n",
    "        ture_LAB = np.array([ture_l,ture_a,ture_b])\n",
    "        ture_LAB = ture_LAB*255\n",
    "        pred_LAB = np.array([ture_l,pred_a,pred_b])\n",
    "        pred_LAB = pred_LAB*255\n",
    "        ture_LAB = np.moveaxis(ture_LAB, 0, -1) #Reshape channeL from  [C, H, W] to [H, W, C]\n",
    "        pred_LAB = np.moveaxis(pred_LAB, 0, -1) #Reshape channeL from  [C, H, W] to [H, W, C]\n",
    "        imgTrueRGB = cv2.cvtColor(np.uint8(ture_LAB), cv2.COLOR_LAB2RGB)\n",
    "        imgPredRGB = cv2.cvtColor(np.uint8(pred_LAB), cv2.COLOR_LAB2RGB)\n",
    "        imgGrayRGB = cv2.cvtColor(imgTrueRGB, cv2.COLOR_RGB2GRAY)\n",
    "        if n == 0 or (n+1) % rowN == 1:\n",
    "            imgTempTrue = imgTrueRGB\n",
    "            imgTempPred = imgPredRGB\n",
    "            imgTempGray = imgGrayRGB\n",
    "        else:\n",
    "            imgTempTrue = np.hstack((imgTempTrue, imgTrueRGB))\n",
    "            imgTempPred = np.hstack((imgTempPred, imgPredRGB))\n",
    "            imgTempGray = np.hstack((imgTempGray, imgGrayRGB))\n",
    "        if (n+1) % rowN == 0:\n",
    "            if n+1 == rowN:\n",
    "                imgGroupTrue = imgTempTrue\n",
    "                imgGroupPred = imgTempPred\n",
    "                imgGroupGray = imgTempGray\n",
    "            else:    \n",
    "                imgGroupTrue = np.vstack((imgGroupTrue, imgTempTrue))\n",
    "                imgGroupPred = np.vstack((imgGroupPred, imgTempPred))\n",
    "                imgGroupGray = np.vstack((imgGroupGray, imgTempGray))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupTrue)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(saveImgPath+'TrueRes.png')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupPred)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(saveImgPath+'PredRes.png')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(imgGroupGray, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(saveImgPath+'GrayRes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "progressive-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"./face_images/\"\n",
    "_, _, files = next(os.walk(img_dir))\n",
    "dataBGR = []\n",
    "dataLAB = []\n",
    "for f1 in files:\n",
    "    img = cv2.imread(img_dir+f1)\n",
    "    dataBGR.append(img)\n",
    "    imageLAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    dataLAB.append(imageLAB)\n",
    "    \n",
    "dataBGR = np.array(dataBGR, dtype = np.float32) #Change data type into float 32.\n",
    "dataLAB = np.array(dataLAB, dtype = np.float32) #Change data type into float 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "healthy-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data types and what they mean!!!\n",
    "# https://scikit-image.org/docs/dev/user_guide/data_types.html\n",
    "# Data type\n",
    "# Range\n",
    "# uint8\n",
    "# 0 to 255\n",
    "# uint16\n",
    "# 0 to 65535\n",
    "# uint32\n",
    "# 0 to 232 - 1\n",
    "# float\n",
    "# -1 to 1 or 0 to 1\n",
    "# int8\n",
    "# -128 to 127\n",
    "# int16\n",
    "# -32768 to 32767\n",
    "# int32\n",
    "# -231 to 231 - 1\n",
    "\n",
    "#According to openCV documents, the range of L*, B*, C* in openCV are expressed as:\n",
    "#Articel ource https://rodrigoberriel.com/2014/11/opencv-color-spaces-splitting-channels/#:~:text=The%20Lab%20ranges%20are%3A,(1%20%3E%20L%20%3E%20255)\n",
    "#0 > L > 100 ⇒ OpenCV range = L*255/100 (1 > L > 255)\n",
    "#-127 > a > 127 ⇒ OpenCV range = a + 128 (1 > a > 255)\n",
    "#-127 > b > 127 ⇒ OpenCV range = b + 128 (1 > b > 255)\n",
    "\n",
    "dataLAB = dataLAB / 255 ##Change reange into [0, 1]\n",
    "dataLAB = np.moveaxis(dataLAB, -1, 1) #Reshape channeL from [B, H, W, C] to [B, C, H, W]\n",
    "dataLAB = dataLAB[torch.randperm(dataLAB.shape[0],generator=torch.random.manual_seed(42))] #shuffle with random seed 42 to make sure each round with same samples pool.\n",
    "lengths = [int(len(dataLAB)*0.9), int(len(dataLAB)*0.1)]\n",
    "trainLAB, testLAB = random_split(dataLAB, lengths ,generator=torch.random.manual_seed(42)) #Shuffle data with random seed 42 before split train and test\n",
    "trainLAB = np.array(trainLAB)\n",
    "testLAB = np.array(testLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "natural-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "trainLABTensor = torch.tensor(trainLAB)\n",
    "trainLABTensorx10 = torch.clone(trainLABTensor)\n",
    "for i in range(9):\n",
    "    trainLABTensorx10 = torch.cat((trainLABTensorx10, torch.clone(trainLABTensor)), 0)\n",
    "    \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToPILImage(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomResizedCrop((128,128),scale=(0.6, 1.0)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "trainLABTensorx10Aug = augementData(trainLABTensorx10,transform) #Augement train data.\n",
    "\n",
    "trainData = [] \n",
    "trainLx10 = [] #Input L*\n",
    "trainAx10 = [] #Matrix a* #Label\n",
    "trainBx10 = [] #Matrix b* #Label\n",
    "trainAvg_ax10 = [] #scalar mean a* #Label\n",
    "trainAvg_bx10 = [] #scalar mean b* #Label\n",
    "i = 0\n",
    "for t in trainLABTensorx10Aug:\n",
    "    meanA = torch.mean(t[1])\n",
    "    meanB = torch.mean(t[2]) #trainLABTensorx10Aug[i,0,:,:]\n",
    "    #print(np.array(trainLABTensorx10Aug[i,0,:,:]).shape)\n",
    "    wh = len(t[0])\n",
    "    trainData.append([torch.reshape(t[0], (1, wh, wh)), torch.tensor([meanA, meanB]), \n",
    "                      torch.tensor([np.array(t[1]), np.array(t[2])])])\n",
    "    trainLx10.append(t[0])\n",
    "    trainAx10.append(t[1])\n",
    "    trainBx10.append(t[2])\n",
    "    trainAvg_ax10.append(meanA)\n",
    "    trainAvg_bx10.append(meanB)\n",
    "    i+=1\n",
    "trainAvg_ax10, trainAvg_bx10 = np.array(trainAvg_ax10), np.array(trainAvg_bx10)     \n",
    "trainlabelAvgABx10 = np.stack((trainAvg_ax10, trainAvg_bx10),axis=1)\n",
    "trainLoader = torch.utils.data.DataLoader(trainData, shuffle=True, batch_size=100)\n",
    "\n",
    "testDataL = testLAB[:,0,:,:] #Input L\n",
    "testDataL = testDataL.reshape((testDataL.shape[0],1,testDataL.shape[1],testDataL.shape[2]))\n",
    "testDataA = testLAB[:,1,:,:] #a* matrix\n",
    "testDataA = testDataA.reshape((testDataA.shape[0],1,testDataA.shape[1],testDataA.shape[2]))\n",
    "testDataB = testLAB[:,2,:,:] #b* matrix\n",
    "testDataB = testDataB.reshape((testDataB.shape[0],1,testDataB.shape[1],testDataB.shape[2]))\n",
    "testAvg_a = testLAB.mean(axis=(2,3))[:,1] #Get label mean of each a* \n",
    "testAvg_b = testLAB.mean(axis=(2,3))[:,2] #Get label mean of each b*\n",
    "testDataL = torch.tensor(testDataL) #Test input\n",
    "testlabelAvgAB = np.stack((testAvg_a, testAvg_b),axis=1)\n",
    "testlabelAvgAB = torch.tensor(testlabelAvgAB) #Test output label\n",
    "\n",
    "testData = []\n",
    "for i in range(len(testDataL)):\n",
    "    testData.append([testDataL[i], testlabelAvgAB[i], torch.tensor([testDataA[i][0], testDataB[i][0]])])\n",
    "testLoader = torch.utils.data.DataLoader(testData, shuffle=False, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "productive-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "netReg = Sequential(\n",
    "            # Defining 1st 2D convolution layer\n",
    "            Conv2d(1, 3, kernel_size=3, stride=1, padding=1), #128@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 2nd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #64@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 3rd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #32@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 4th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #16@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 5th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #8@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 6th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #4@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 7th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #2@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            #MaxPool2d(kernel_size=2, stride=2),\n",
    "            Flatten(),\n",
    "            Linear(3 * 2 * 2, 2)\n",
    "        )\n",
    "\n",
    "PATH = '../TrainedModel/RegCombWithLR0.1EP1000.pth'\n",
    "netReg.load_state_dict(torch.load(PATH))\n",
    "netReg = netReg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "trainDataWithPredAB = []\n",
    "for i, data in enumerate(trainLoader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    inputs, labelsAvgAB, labelsMatAB = data[0].cuda(), data[1].cuda(), data[2].cuda() #Reg\n",
    "    predAvgAB = netReg(inputs)\n",
    "    \n",
    "    #trainDataWithPredAB.append([testDataL[i], testlabelAvgAB[i], torch.tensor([testDataA[i][0], testDataB[i][0]])])\n",
    "    #print(inputs[0,0,1,1])\n",
    "    inputsNP = inputs.cpu().data.numpy()\n",
    "    labelsAvgAB = labelsAvgAB.cpu().data.numpy()\n",
    "    labelsMatAB = labelsMatAB.cpu().data.numpy() \n",
    "    predAvgAB = predAvgAB.cpu().data.numpy() \n",
    "    \n",
    "    w = inputsNP[0].shape[-2]\n",
    "    h = inputsNP[0].shape[-1]\n",
    "    for j in range(len(inputs)):\n",
    "        predMatA = np.zeros((w,h)) + predAvgAB[j][0]\n",
    "        predMatB = np.zeros((w,h)) + predAvgAB[j][1]\n",
    "        trainDataWithPredAB.append([torch.tensor([inputsNP[j][0], predMatA, predMatB], dtype = torch.float32), \n",
    "                                    torch.tensor([labelsAvgAB[j][0], labelsAvgAB[j][1]], dtype = torch.float32), \n",
    "                                    torch.tensor([labelsMatAB[j][0], labelsMatAB[j][1]], dtype = torch.float32)])\n",
    "\n",
    "trainLoaderWithPredAB = torch.utils.data.DataLoader(trainDataWithPredAB, shuffle=True, batch_size=100)        \n",
    "\n",
    "testDataWithPredAB = []\n",
    "for i, data in enumerate(testLoader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    inputs, labelsAvgAB, labelsMatAB = data[0].cuda(), data[1].cuda(), data[2].cuda()\n",
    "    predAvgAB = netReg(inputs)\n",
    "    \n",
    "    #trainDataWithPredAB.append([testDataL[i], testlabelAvgAB[i], torch.tensor([testDataA[i][0], testDataB[i][0]])])\n",
    "    #print(inputs[0,0,1,1])\n",
    "    inputsNP = inputs.cpu().data.numpy()\n",
    "    labelsAvgAB = labelsAvgAB.cpu().data.numpy()\n",
    "    labelsMatAB = labelsMatAB.cpu().data.numpy() \n",
    "    predAvgAB = predAvgAB.cpu().data.numpy() \n",
    "    \n",
    "    w = inputsNP[0].shape[-2]\n",
    "    h = inputsNP[0].shape[-1]\n",
    "    for j in range(len(inputs)):\n",
    "        predMatA = np.zeros((w,h)) + predAvgAB[j][0]\n",
    "        predMatB = np.zeros((w,h)) + predAvgAB[j][1]\n",
    "        testDataWithPredAB.append([torch.tensor([inputsNP[j][0], predMatA, predMatB], dtype = torch.float32), \n",
    "                                    torch.tensor([labelsAvgAB[j][0], labelsAvgAB[j][1]], dtype = torch.float32), \n",
    "                                    torch.tensor([labelsMatAB[j][0], labelsMatAB[j][1]], dtype = torch.float32)])\n",
    "#torch.tensor(np.array([inputsNP[j][0],predMatA,predMatB]))\n",
    "testLoaderWithPredAB = torch.utils.data.DataLoader(testDataWithPredAB, shuffle=False, batch_size=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColorizingCombWithLR0.1EP1000\n",
    "netClo = Sequential(\n",
    "            # Defining 1st 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #128@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 2nd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #64@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 3rd 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #32@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining 4th 2D convolution layer\n",
    "            Conv2d(3, 3, kernel_size=3, stride=1, padding=1), #16@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@16@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@32@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 3, 4, stride=2, padding=1), #@64@3\n",
    "            BatchNorm2d(3),\n",
    "            ReLU(inplace=True),\n",
    "            ConvTranspose2d(3, 2, 4, stride=2, padding=1), #@128@3\n",
    "            Sigmoid()\n",
    "        )\n",
    "\n",
    "PATH = '../TrainedModel/ColorizingCombWithLR0.1EP1000.pth'\n",
    "netClo.load_state_dict(torch.load(PATH))\n",
    "netClo = netClo.cuda()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveImgPath = '../TrainTestImagesRes/ColorizingComb-'\n",
    "savePathtrain = saveImgPath+'train-'\n",
    "train_loss = 0.0\n",
    "for i, data in enumerate(trainLoaderWithPredAB, 0):\n",
    "    #print(data)\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    inputs, labels = data[0].cuda(), data[2].cuda() #Color\n",
    "    \n",
    "    outputs = netClo(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # print statistics\n",
    "    train_loss += loss.item()\n",
    "    saveRes2Img(inputs, labels, outputs,savePathtrain) \n",
    "    break\n",
    "logStr = 'Train MSE_Loss: %.10f' % (train_loss/ (i+1))\n",
    "print(logStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePathtest = saveImgPath+'test-'\n",
    "test_loss = 0\n",
    "for i, data in enumerate(testLoaderWithPredAB, 0):\n",
    "    inputs, labels = data[0].cuda(), data[2].cuda() #Color\n",
    "    outputs = netClo(inputs)\n",
    "\n",
    "    loss = criterion(outputs, labels)\n",
    "    test_loss += loss.item()\n",
    "    saveRes2Img(inputs, labels, outputs,savePathtest) \n",
    "n_samples = (i+1)*len(outputs)       \n",
    "\n",
    "logStr = 'Test MSE of the network on the %d test samples: %.10f' % (n_samples, test_loss/(i+1))\n",
    "print(logStr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-yacht",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
